{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4826,  2.7383, -2.8546,  0.9479],\n",
      "        [-1.0390, -0.8626, -0.1026, -0.4092]])\n",
      "torch.Size([2, 4])\n",
      "torch.FloatTensor\n",
      "<class 'torch.Tensor'>\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import  torch\n",
    "a=torch.randn(2,4)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.type())\n",
    "print(type(a))\n",
    "print(isinstance(a,torch.IntTensor))\n",
    "print(isinstance(a,torch.FloatTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1000)\n",
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "b=torch.tensor(2.1)\n",
    "print(b)\n",
    "print(b.shape)\n",
    "print(b.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "b=torch.tensor([2.1])\n",
    "print(b.shape)\n",
    "print(b.size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=torch.tensor([1.3,2.6])\n",
    "b.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-2.3470e+10])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0., 0.])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3,1]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([-2.3470e+10,  4.5668e-41,  3.2650e-24])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(3).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.3734, -1.5454,  0.0581,  0.2323],\n        [-1.0367, -1.0539, -0.4568, -0.0616]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 4])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(2,4).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2000, 1.3000, 2.1000],\n        [3.2000, 2.5000, 1.6000]])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1., 1.])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "(2,)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones(2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1., 1.], dtype=torch.float64)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.ones(2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.ones(2)).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2000, 1.3000, 2.1000],\n        [3.2000, 2.5000, 1.6000]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]]).shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]]).shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]]).size(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([[1.2,1.3,2.1],[3.2,2.5,1.6]]).size(1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[1.2000, 1.3000, 2.1000],\n         [3.2000, 2.5000, 1.6000]],\n\n        [[3.6000, 6.3000, 5.1000],\n         [7.2000, 3.5000, 4.6000]]])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 2, 3])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ]).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ]).shape[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ]).shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "3"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ]).shape[2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.2000, 1.3000, 2.1000],\n        [3.2000, 2.5000, 1.6000]])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ])\n",
    "a[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3.6000, 6.3000, 5.1000],\n        [7.2000, 3.5000, 4.6000]])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ])\n",
    "a[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 2, 3]"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.FloatTensor(\n",
    "     [\n",
    "         [[1.2,1.3,2.1],[3.2,2.5,1.6]],\n",
    "         [[3.6,6.3,5.1],[7.2,3.5,4.6]]\n",
    "     ])\n",
    "list(a.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好\n"
     ]
    }
   ],
   "source": [
    "\n",
    "a=torch.rand(9,1,28,28)#四维矩阵适合卷积神经网络\n",
    "a\n",
    "print('你好')\n",
    "print('你好吗')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "7056"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.rand(9,1,28,28)#四维矩阵适合卷积神经网络\n",
    "a.numel()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "4"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(9,1,28,28)#四维矩阵适合卷积神经网络\n",
    "a.dim()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.0000, 3.2000], dtype=torch.float64)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#从numpy引入tensor\n",
    "import numpy\n",
    "a=numpy.array([2,3.2])\n",
    "torch.from_numpy(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=numpy.ones([2,3])#值为1而取名ones\n",
    "torch.from_numpy(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.1000, 3.6000])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor接受shape数据维度;tensor接受具体数据numpy,列表,\n",
    "torch.tensor([3.1,3.6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[3.3995e-09, 3.0651e-41, 3.4179e-09, 3.0651e-41],\n        [8.9683e-44, 0.0000e+00, 1.1210e-43, 0.0000e+00],\n        [0.0000e+00, 0.0000e+00, 3.5073e-09, 3.0651e-41]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor接受shape数据维度;tensor接受具体数据numpy,列表,\n",
    "torch.FloatTensor(3,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 9.1835e-41, 0.0000e+00]],\n\n        [[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n         [0.0000e+00, 0.0000e+00, 6.0995e+14, 4.5668e-41]]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor接受shape数据维度;tensor接受具体数据numpy,列表,\n",
    "#Tensor使用的默认数据类型\n",
    "torch.FloatTensor(2,3,4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3.1000, 3.6000])"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor也可以接受现成数据的情况,尽量少用\n",
    "torch.FloatTensor([3.1,3.6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[2.5516e+19, 4.5668e-41, 2.5516e+19],\n        [4.5668e-41, 4.4842e-44, 0.0000e+00]])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(2,3)#生成未初始化的数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([2.5516e+19])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(1)#生成未初始化的数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.DoubleTensor'"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.tensor([5.2,3]).type()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "'torch.LongTensor'"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.tensor([5,3]).type()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2178, 0.1104, 0.6771],\n        [0.8065, 0.3951, 0.8023]])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(2,3)#生成随机的均匀的0-1之间的数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.4504, 0.9669, 0.4353],\n        [0.1817, 0.2417, 0.0922],\n        [0.5074, 0.3863, 0.6724],\n        [0.4532, 0.9165, 0.6650]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3)#生成随机的均匀的0-1之间的数据\n",
    "torch.rand_like(a)\n",
    "#rand_like更加通用可以获取一个shape来生成随机的均匀的0-1之间的数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2103, 0.9001, 0.1816],\n        [0.0797, 0.1690, 0.7149],\n        [0.2505, 0.9953, 0.8008],\n        [0.5319, 0.1053, 0.5546]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(4,3)#生成正态分布N(0,1)的0-1之间的数据"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6, 6, 6],\n        [6, 6, 6]])"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([2,3],6)#全部值为6"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(6)"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([],6)#标量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([6])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full([1],6)#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 2, 4, 6, 8])"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10,2)#torch里面不建议使用range"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0000,  3.3333,  6.6667, 10.0000])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,10,steps=4)#4等分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.0000,  0.5263,  1.0526,  1.5789,  2.1053,  2.6316,  3.1579,  3.6842,\n         4.2105,  4.7368,  5.2632,  5.7895,  6.3158,  6.8421,  7.3684,  7.8947,\n         8.4211,  8.9474,  9.4737, 10.0000])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,10,steps=20)#20等分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1.0000, 0.7743, 0.5995, 0.4642, 0.3594, 0.2783, 0.2154, 0.1668, 0.1292,\n        0.1000])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.logspace(0,-1,steps=10)#*10"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 0., 0.],\n        [0., 0., 0.]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.]])"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(2, 3)#对角线全为1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3, 3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 28, 28])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([28, 28])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[0,0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([])"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[0,0,15,20].shape#像素点标量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4382)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[0,0,15,20]#像素点标量"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 28, 28])"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2].shape#取两张"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1, 28, 28])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2,:1].shape#取两张的一个通道"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 1, 28, 28])"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2,:1,:,:].shape#取两张的一个通道"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[0.4447, 0.4781, 0.7509,  ..., 0.0457, 0.1021, 0.7490],\n          [0.8691, 0.9869, 0.0925,  ..., 0.3882, 0.7877, 0.5402],\n          [0.6129, 0.3195, 0.3560,  ..., 0.8103, 0.8543, 0.7815],\n          ...,\n          [0.8656, 0.3143, 0.6905,  ..., 0.6107, 0.2750, 0.9405],\n          [0.0795, 0.3790, 0.7687,  ..., 0.7279, 0.9212, 0.9394],\n          [0.6446, 0.1612, 0.7189,  ..., 0.5325, 0.8837, 0.9191]],\n\n         [[0.8531, 0.6746, 0.6651,  ..., 0.5806, 0.9308, 0.5945],\n          [0.1172, 0.8937, 0.2230,  ..., 0.6722, 0.6970, 0.3900],\n          [0.9972, 0.3366, 0.6393,  ..., 0.9663, 0.2771, 0.2510],\n          ...,\n          [0.8561, 0.1801, 0.2561,  ..., 0.9915, 0.8435, 0.2286],\n          [0.9930, 0.1559, 0.7491,  ..., 0.1816, 0.0431, 0.6269],\n          [0.3632, 0.4005, 0.9515,  ..., 0.2259, 0.2981, 0.9866]]],\n\n\n        [[[0.0385, 0.0541, 0.9255,  ..., 0.4051, 0.1651, 0.2283],\n          [0.0067, 0.6564, 0.8748,  ..., 0.4772, 0.5711, 0.3900],\n          [0.7215, 0.6595, 0.1045,  ..., 0.5911, 0.6608, 0.4692],\n          ...,\n          [0.9118, 0.7859, 0.5001,  ..., 0.1811, 0.3440, 0.9955],\n          [0.4854, 0.3169, 0.0791,  ..., 0.5475, 0.5314, 0.8386],\n          [0.3840, 0.5384, 0.7592,  ..., 0.6183, 0.9434, 0.1889]],\n\n         [[0.7087, 0.9783, 0.6809,  ..., 0.8488, 0.9116, 0.2711],\n          [0.1742, 0.2547, 0.9697,  ..., 0.6114, 0.4265, 0.7762],\n          [0.4922, 0.8134, 0.5843,  ..., 0.7486, 0.8121, 0.4967],\n          ...,\n          [0.9004, 0.3816, 0.3709,  ..., 0.3021, 0.6028, 0.8358],\n          [0.2252, 0.0260, 0.7875,  ..., 0.7796, 0.3349, 0.4686],\n          [0.2954, 0.8236, 0.0821,  ..., 0.7906, 0.6831, 0.2870]]]])"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2,:-1,:,:].shape#-1:从最后一个元素取到最后,就是取了一个元素\n",
    "#正向从0开始,反向从-1开始"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 2, 14, 14])"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2,:-1,0:28:2,0:28:2].shape#0:28:2隔行采样\n",
    "#正向从0开始,反向从-1开始"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#index_select可以对某个维度针对性采样"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 3, 7, 28])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a.index_select(2,torch.arange(7)).shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 3, 28, 28])"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[...].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 28, 28])"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[1,...].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 28, 28])"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:,1,...].shape#...表示其余的每个维度都选取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 28, 28])"
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2,1,...].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 3, 28, 16])"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[...,:16].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 3, 20, 16])"
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[...,:20,:16].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3, 28, 16])"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,28,28)#bitchsize,channel,long,height\n",
    "a[:2,...,:16].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#masked_select()可以根据mask来选择元素\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0.2574, 0.5106, 0.9052])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src=torch.rand(2,3)\n",
    "torch.take(src,torch.tensor([0,2,5]))#take将tensor打平,再索引元素"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.0456, 0.1177, 0.0224,  ..., 0.3625, 0.1895, 0.7850],\n        [0.0815, 0.6169, 0.2712,  ..., 0.6650, 0.3968, 0.8011],\n        [0.0832, 0.7407, 0.5257,  ..., 0.0629, 0.6883, 0.6146],\n        [0.7596, 0.2585, 0.8046,  ..., 0.2533, 0.8347, 0.2172]])"
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view\n",
    "#bitchsize,channel,long,height\n",
    "a=torch.rand(4,1,28,28)\n",
    "a.view(4,28*28)#适用于全链接层的输入"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[4, 784]' is invalid for input of size 9408",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3028/4232529274.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;31m#bitchsize,channel,long,height\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m28\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m28\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m28\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m28\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m#适用于全链接层的输入\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: shape '[4, 784]' is invalid for input of size 9408"
     ]
    }
   ],
   "source": [
    "#view\n",
    "#bitchsize,channel,long,height\n",
    "a=torch.rand(4,3,28,28)\n",
    "a.view(4,28*28)#适用于全链接层的输入"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.2049, 0.4424, 0.9131,  ..., 0.2499, 0.9601, 0.3144],\n        [0.1696, 0.3707, 0.8271,  ..., 0.9318, 0.2526, 0.2913],\n        [0.4637, 0.9646, 0.9386,  ..., 0.6793, 0.5893, 0.9408],\n        ...,\n        [0.1143, 0.2069, 0.7124,  ..., 0.9967, 0.2573, 0.8558],\n        [0.3003, 0.5629, 0.2751,  ..., 0.7107, 0.1229, 0.3117],\n        [0.0498, 0.7953, 0.0384,  ..., 0.1650, 0.7921, 0.3981]])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view\n",
    "#bitchsize,channel,long,height\n",
    "a=torch.rand(4,1,28,28)#维度为1时有没有看不影响数据量,而是影响对数据的分组理解\n",
    "a.view(4,28*28)#将一张图看成一行28*28的行,适用于全链接层的输入\n",
    "a.view(4*28,28)#以行为单位考察,有4*28行"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a=torch.rand(4,1,28,28)\n",
    "a.view(4*1,28,28)#将一张图看成一行28*28的矩阵,适用于全链接层的输入\n",
    "#view会丢失维度存储信息,恢复时需要额外的信息才可以\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 1, 28, 28])"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,1,28,28)\n",
    "a.unsqueeze(0)\n",
    "a.unsqueeze(0).shape#多加了一个括号扩起来\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 1, 28, 28, 1])"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,1,28,28)\n",
    "a.unsqueeze(0)\n",
    "a.unsqueeze(-1).shape#在索引-1之前插入"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 1, 28, 1, 28])"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,1,28,28)\n",
    "a.unsqueeze(0)\n",
    "a.unsqueeze(-2).shape#多加了一个括号扩起来"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32])"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squeeze压缩,抛弃维度信息不关心,保留数据本身\n",
    "#[1,32,1,1]=>[32]原来32个通道各有一个数据,现在仍然有32个数据,不管那一类\n",
    "a=torch.rand(1,32,1,1)\n",
    "a.squeeze().shape#不传递参数表示压缩所有为1的维度"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([32, 1, 1])"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squeeze压缩,抛弃维度信息不关心,保留数据本身\n",
    "#[1,32,1,1]=>[32]原来32个通道各有一个数据,现在仍然有32个数据,不管那一类\n",
    "a=torch.rand(1,32,1,1)\n",
    "a.squeeze(0).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 32, 1])"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#squeeze压缩,抛弃维度信息不关心,保留数据本身\n",
    "#[1,32,1,1]=>[32]原来32个通道各有一个数据,现在仍然有32个数据,不管那一类\n",
    "a=torch.rand(1,32,1,1)\n",
    "a.squeeze(-1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 32, 14, 14])"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#维度拓展\n",
    "a=torch.rand(1,32,1,1)\n",
    "b=torch.rand(4,32,14,14)#原来为1的维度才可以拓展,不为1没法复制\n",
    "a.expand(4,32,14,14).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (14) must match the existing size (4) at non-singleton dimension 2.  Target sizes: [4, 32, 14, 14].  Tensor sizes: [1, 32, 4, 1]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3028/708656520.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m14\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m14\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m#原来为1的维度才可以拓展,不为1没法复制\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexpand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m14\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m14\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: The expanded size of the tensor (14) must match the existing size (4) at non-singleton dimension 2.  Target sizes: [4, 32, 14, 14].  Tensor sizes: [1, 32, 4, 1]"
     ]
    }
   ],
   "source": [
    "#维度拓展\n",
    "a=torch.rand(1,32,4,1)\n",
    "b=torch.rand(4,32,14,14)#显然4=>14没法多次复制实现\n",
    "a.expand(4,32,14,14).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 32, 8, 14])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repeat\n",
    "a=torch.rand(1,32,4,1)\n",
    "a.repeat(4,1,2,14).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.6422, 0.7621, 0.9805],\n        [0.7984, 0.5452, 0.8382],\n        [0.4120, 0.4262, 0.0550],\n        [0.9439, 0.9548, 0.8385]])"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵转置\n",
    "a=torch.rand(3,4)\n",
    "a.t()#只是用于矩阵"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 32, 32, 3])"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transpose\n",
    "a=torch.rand(4,3,32,32)\n",
    "a.shape\n",
    "a.transpose(1,3).shape#交换1,3维度\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3028/3876401300.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0ma\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtranspose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m32\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "#transpose\n",
    "a=torch.rand(4,3,32,32)\n",
    "a.shape\n",
    "a.transpose(1,3).view(4,3*32*32).view(4,3,32,32)\n",
    "#维度变换导致数据不连续"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[4.3067e-01, 8.3133e-02, 6.0404e-01,  ..., 2.2435e-02,\n           1.8692e-01, 8.7619e-01],\n          [4.8460e-01, 1.6701e-01, 4.2860e-01,  ..., 1.3284e-01,\n           9.2028e-01, 7.2683e-01],\n          [4.4439e-01, 3.3718e-03, 4.0584e-01,  ..., 4.8194e-02,\n           4.9164e-01, 6.7254e-01],\n          ...,\n          [5.1805e-01, 9.0596e-03, 8.1282e-01,  ..., 9.0021e-01,\n           4.8700e-01, 3.0087e-01],\n          [3.5393e-01, 2.4444e-01, 2.8306e-01,  ..., 7.5470e-02,\n           4.7585e-01, 2.4910e-01],\n          [6.4154e-01, 7.3146e-03, 9.9149e-01,  ..., 8.1013e-01,\n           4.4816e-01, 9.9249e-01]],\n\n         [[5.8441e-01, 4.6009e-01, 7.3179e-01,  ..., 7.2992e-02,\n           8.0750e-01, 1.6409e-01],\n          [5.0579e-02, 9.4801e-01, 2.9821e-01,  ..., 7.2075e-01,\n           1.1616e-01, 4.2064e-01],\n          [6.0547e-01, 3.3937e-01, 3.0030e-01,  ..., 9.1416e-01,\n           8.5680e-01, 1.6111e-01],\n          ...,\n          [7.8615e-01, 8.2155e-01, 1.5964e-01,  ..., 2.5458e-01,\n           5.3356e-01, 8.7568e-01],\n          [8.0032e-01, 3.5752e-01, 2.5459e-01,  ..., 3.9709e-01,\n           4.9438e-01, 3.6876e-01],\n          [4.2928e-01, 9.1049e-01, 1.6271e-01,  ..., 4.3682e-01,\n           1.1512e-01, 3.7049e-01]],\n\n         [[8.7549e-01, 7.8890e-01, 9.0326e-01,  ..., 4.4957e-02,\n           7.2515e-01, 6.4196e-01],\n          [2.1096e-01, 6.9980e-01, 1.4314e-01,  ..., 7.0623e-01,\n           2.5513e-01, 6.1699e-02],\n          [1.8847e-01, 1.1946e-01, 1.6285e-03,  ..., 9.8283e-01,\n           4.7875e-01, 3.1955e-01],\n          ...,\n          [1.9687e-01, 8.3635e-01, 2.4238e-01,  ..., 6.2565e-01,\n           2.8104e-01, 3.3936e-01],\n          [9.4278e-01, 9.5117e-01, 8.3714e-01,  ..., 6.0719e-01,\n           9.6459e-01, 6.7439e-01],\n          [3.4702e-01, 1.5906e-01, 6.2335e-01,  ..., 5.5889e-02,\n           8.6297e-01, 9.3296e-01]]],\n\n\n        [[[7.6375e-01, 5.1840e-01, 3.5855e-01,  ..., 6.2837e-01,\n           7.9355e-01, 7.3758e-01],\n          [7.8044e-01, 4.6757e-01, 8.1648e-01,  ..., 6.7820e-01,\n           9.2844e-02, 4.8333e-01],\n          [4.5557e-01, 3.6260e-01, 8.6760e-01,  ..., 1.4150e-01,\n           6.7521e-01, 7.5161e-01],\n          ...,\n          [3.4771e-01, 7.7014e-01, 9.7286e-01,  ..., 3.7898e-01,\n           6.3172e-01, 2.9507e-01],\n          [9.6620e-01, 5.7760e-01, 8.5296e-01,  ..., 2.1635e-01,\n           2.2481e-01, 4.1133e-01],\n          [5.8804e-01, 1.6000e-01, 2.5900e-02,  ..., 3.2968e-01,\n           8.7775e-01, 4.5993e-01]],\n\n         [[5.8731e-01, 1.3628e-01, 8.0792e-02,  ..., 1.7941e-01,\n           6.3988e-02, 4.0359e-01],\n          [9.8192e-01, 5.0156e-01, 5.1875e-01,  ..., 8.1058e-01,\n           4.1081e-01, 5.9528e-01],\n          [2.3296e-01, 8.4646e-01, 5.9932e-01,  ..., 6.7659e-01,\n           4.3367e-01, 5.2350e-01],\n          ...,\n          [2.9228e-01, 7.7045e-01, 7.5316e-01,  ..., 8.1906e-01,\n           1.2348e-01, 9.1662e-01],\n          [8.2785e-01, 7.0158e-01, 2.6736e-01,  ..., 9.2931e-01,\n           5.8761e-02, 3.4155e-01],\n          [5.3935e-01, 5.9339e-01, 1.7716e-01,  ..., 6.6495e-01,\n           9.7880e-01, 1.8406e-01]],\n\n         [[5.5704e-01, 9.7142e-01, 9.9059e-01,  ..., 2.5219e-01,\n           9.4895e-01, 4.0076e-01],\n          [1.2529e-01, 5.9644e-01, 1.7343e-01,  ..., 1.7262e-01,\n           8.9094e-01, 2.7711e-01],\n          [6.7489e-01, 9.1501e-01, 7.7815e-01,  ..., 3.9386e-01,\n           5.8363e-01, 4.7486e-01],\n          ...,\n          [2.2320e-01, 7.3615e-01, 5.9739e-01,  ..., 7.8301e-01,\n           8.0676e-01, 4.6511e-01],\n          [6.9642e-01, 2.5955e-01, 5.0273e-01,  ..., 5.2368e-01,\n           2.2810e-01, 3.6162e-01],\n          [1.9086e-01, 3.9177e-01, 6.1063e-01,  ..., 5.5570e-04,\n           5.4944e-01, 7.6066e-01]]],\n\n\n        [[[9.3425e-01, 2.2041e-01, 1.6692e-01,  ..., 6.4511e-01,\n           5.6118e-01, 7.2694e-01],\n          [9.1936e-01, 5.3888e-01, 2.2651e-01,  ..., 4.2953e-01,\n           9.3902e-01, 1.7509e-01],\n          [3.9600e-01, 9.9381e-01, 4.4679e-02,  ..., 6.5116e-01,\n           8.9855e-01, 7.4472e-01],\n          ...,\n          [4.9362e-01, 7.9822e-01, 2.4227e-01,  ..., 2.1858e-01,\n           9.1208e-01, 6.5570e-01],\n          [9.3689e-01, 3.5262e-01, 4.1982e-01,  ..., 8.6998e-01,\n           8.9129e-01, 7.6704e-01],\n          [4.0814e-01, 1.3834e-01, 9.8605e-01,  ..., 2.5238e-01,\n           6.9110e-01, 4.7145e-01]],\n\n         [[6.2444e-01, 1.0330e-01, 5.9542e-01,  ..., 5.7409e-01,\n           5.3646e-01, 2.7828e-01],\n          [3.3720e-01, 8.1372e-01, 8.4679e-01,  ..., 3.4247e-01,\n           3.1456e-01, 6.1376e-01],\n          [5.6852e-01, 1.5628e-01, 5.9169e-01,  ..., 7.3336e-01,\n           3.5590e-02, 1.0976e-01],\n          ...,\n          [8.2390e-01, 8.6788e-01, 2.3631e-01,  ..., 4.5315e-01,\n           1.9506e-01, 1.9036e-01],\n          [1.7050e-01, 7.5682e-02, 3.3276e-01,  ..., 9.6764e-01,\n           6.9683e-01, 3.7330e-01],\n          [9.0058e-01, 7.5647e-01, 3.6373e-01,  ..., 9.2334e-01,\n           3.3485e-02, 3.1853e-01]],\n\n         [[6.9005e-01, 4.6576e-01, 3.6887e-01,  ..., 3.3396e-01,\n           6.1736e-01, 4.1847e-01],\n          [7.0312e-01, 6.8608e-01, 8.2970e-01,  ..., 3.3912e-01,\n           2.9573e-01, 1.1784e-01],\n          [4.1450e-01, 2.6782e-01, 8.2344e-01,  ..., 6.2906e-01,\n           9.8931e-02, 6.9091e-02],\n          ...,\n          [5.8027e-01, 5.5617e-01, 3.8953e-01,  ..., 5.1336e-01,\n           3.1751e-01, 7.1632e-01],\n          [3.3872e-01, 6.6525e-01, 1.9933e-01,  ..., 8.2249e-01,\n           3.5025e-02, 8.7002e-01],\n          [7.7788e-01, 5.4177e-01, 1.6896e-01,  ..., 7.6924e-01,\n           9.5743e-01, 1.1906e-01]]],\n\n\n        [[[4.3969e-01, 1.6091e-01, 2.5851e-01,  ..., 1.6878e-01,\n           7.3097e-01, 9.2511e-01],\n          [3.5760e-01, 3.9856e-01, 2.0156e-01,  ..., 8.8945e-01,\n           7.6006e-01, 7.6291e-01],\n          [2.8899e-01, 5.2043e-01, 9.0233e-02,  ..., 8.8869e-01,\n           3.3409e-01, 5.9970e-01],\n          ...,\n          [6.6839e-01, 7.5661e-01, 2.4997e-01,  ..., 7.9722e-01,\n           7.2658e-01, 4.4342e-01],\n          [3.3817e-01, 8.6879e-01, 7.5911e-01,  ..., 5.3172e-01,\n           9.6646e-01, 1.9955e-01],\n          [7.8769e-01, 5.6210e-03, 2.6165e-01,  ..., 1.3518e-01,\n           6.3972e-01, 5.8243e-01]],\n\n         [[8.0076e-01, 9.4493e-01, 2.0355e-01,  ..., 2.2676e-01,\n           3.0883e-01, 5.1396e-01],\n          [4.9884e-01, 5.0767e-01, 7.2210e-01,  ..., 2.7786e-01,\n           6.1745e-01, 4.0987e-01],\n          [1.3765e-01, 6.0555e-01, 4.6245e-01,  ..., 6.9135e-01,\n           8.1088e-01, 8.7092e-01],\n          ...,\n          [8.6423e-01, 8.9903e-01, 4.7295e-01,  ..., 2.5327e-01,\n           2.3386e-01, 9.9428e-01],\n          [1.9010e-01, 3.2646e-01, 8.5443e-01,  ..., 4.1369e-01,\n           6.8121e-01, 7.3673e-01],\n          [9.9619e-01, 3.3837e-01, 3.1864e-01,  ..., 6.2054e-01,\n           9.9934e-01, 6.1244e-01]],\n\n         [[2.1657e-01, 9.1751e-01, 8.4830e-02,  ..., 7.7933e-01,\n           8.0687e-01, 2.4874e-01],\n          [5.2388e-01, 5.2394e-01, 5.6887e-01,  ..., 4.1366e-01,\n           6.7261e-02, 6.6026e-01],\n          [8.0230e-01, 2.7875e-01, 6.6548e-01,  ..., 6.3471e-01,\n           9.9119e-01, 9.1502e-01],\n          ...,\n          [8.5467e-01, 9.5988e-01, 5.1272e-01,  ..., 7.2976e-01,\n           9.3235e-01, 6.1938e-01],\n          [9.4373e-01, 3.5630e-01, 4.4353e-01,  ..., 1.1550e-01,\n           4.5396e-01, 7.3095e-01],\n          [2.6461e-01, 6.3361e-01, 7.6108e-01,  ..., 7.7626e-01,\n           4.9288e-01, 7.2418e-02]]]])"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transpose\n",
    "a=torch.rand(4,3,32,32)\n",
    "a.shape\n",
    "a.transpose(1,3).contiguous().view(4,3*32*32).view(4,3,32,32)#contiguous()实现连续化,#不过还是错误的"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[5.4828e-01, 8.3180e-01, 9.5768e-01,  ..., 6.5977e-01,\n           3.7466e-01, 8.3000e-01],\n          [1.8124e-01, 8.8283e-01, 7.2073e-01,  ..., 2.2556e-01,\n           3.0337e-02, 7.9313e-01],\n          [5.8105e-02, 7.7306e-01, 1.5377e-01,  ..., 4.7403e-01,\n           9.2103e-01, 4.1398e-01],\n          ...,\n          [2.5378e-01, 5.2989e-01, 9.5435e-01,  ..., 3.3101e-01,\n           3.8319e-01, 2.6550e-01],\n          [6.6456e-01, 3.8422e-01, 7.7271e-02,  ..., 5.9150e-01,\n           2.1570e-01, 5.1886e-01],\n          [9.8543e-01, 2.3678e-01, 1.5065e-01,  ..., 9.8475e-01,\n           4.5740e-01, 7.1265e-01]],\n\n         [[4.4879e-01, 1.2950e-02, 7.1129e-01,  ..., 9.9164e-01,\n           1.7414e-01, 4.5326e-01],\n          [3.1828e-01, 9.3233e-01, 5.4462e-01,  ..., 5.2155e-01,\n           5.7119e-01, 1.9552e-01],\n          [3.5620e-01, 1.2074e-01, 4.8139e-02,  ..., 8.3267e-01,\n           1.9583e-01, 3.1247e-01],\n          ...,\n          [8.1292e-02, 7.3352e-01, 2.2487e-01,  ..., 4.2667e-01,\n           7.3526e-01, 1.8056e-01],\n          [7.0625e-01, 5.2608e-01, 7.8901e-01,  ..., 6.6511e-01,\n           7.9445e-01, 7.9116e-01],\n          [4.2889e-01, 8.3986e-01, 1.6755e-01,  ..., 1.6962e-01,\n           9.6901e-01, 3.7722e-01]],\n\n         [[1.5727e-01, 1.9820e-01, 6.3216e-02,  ..., 6.9252e-01,\n           1.8287e-01, 5.4557e-01],\n          [5.3594e-01, 4.2168e-01, 8.4990e-01,  ..., 7.2674e-01,\n           4.7951e-01, 7.6200e-01],\n          [3.5449e-01, 7.3257e-01, 4.8271e-01,  ..., 5.8361e-01,\n           4.9333e-01, 9.0180e-01],\n          ...,\n          [7.0981e-01, 8.1905e-01, 6.6533e-01,  ..., 6.1037e-01,\n           2.4627e-01, 5.7920e-01],\n          [5.3951e-02, 5.3099e-01, 7.6613e-01,  ..., 1.0187e-02,\n           7.5682e-02, 7.9273e-01],\n          [7.3563e-01, 1.5183e-01, 5.1776e-01,  ..., 6.8829e-01,\n           7.0073e-01, 4.0356e-01]]],\n\n\n        [[[9.6304e-01, 7.4503e-01, 1.5938e-01,  ..., 4.4575e-01,\n           6.4197e-01, 6.1033e-01],\n          [8.6873e-01, 7.2753e-01, 1.9159e-01,  ..., 9.0750e-01,\n           6.6077e-01, 2.5928e-01],\n          [4.0807e-01, 3.7687e-02, 8.7224e-01,  ..., 2.9625e-01,\n           9.5798e-01, 9.5059e-04],\n          ...,\n          [5.8623e-01, 8.7502e-01, 8.4982e-01,  ..., 1.3321e-01,\n           7.0664e-01, 8.7469e-01],\n          [1.4612e-01, 6.3728e-01, 4.4175e-01,  ..., 1.2408e-01,\n           8.0139e-01, 1.0786e-01],\n          [2.1649e-01, 1.3189e-01, 7.2223e-01,  ..., 7.0983e-01,\n           9.5921e-01, 3.3965e-01]],\n\n         [[8.2918e-01, 7.0875e-01, 3.2067e-01,  ..., 4.2579e-01,\n           5.5908e-02, 9.0592e-01],\n          [6.6225e-01, 2.6554e-01, 4.0585e-01,  ..., 5.5536e-01,\n           2.8724e-01, 2.0260e-01],\n          [1.4865e-01, 1.0054e-01, 6.4723e-01,  ..., 3.2282e-01,\n           1.5206e-01, 5.4277e-01],\n          ...,\n          [4.9825e-01, 3.0357e-01, 7.9685e-01,  ..., 8.4053e-01,\n           5.8200e-01, 2.7454e-01],\n          [9.2091e-01, 2.8533e-01, 6.7193e-01,  ..., 8.4999e-01,\n           5.7069e-01, 3.2179e-01],\n          [5.5767e-01, 3.9686e-01, 3.6604e-01,  ..., 6.0681e-02,\n           9.2881e-01, 5.1018e-01]],\n\n         [[1.4449e-01, 5.0589e-01, 7.3175e-01,  ..., 7.3346e-01,\n           7.1938e-01, 6.4319e-02],\n          [5.2401e-02, 4.2292e-01, 2.9920e-01,  ..., 7.7629e-01,\n           1.7419e-01, 9.2313e-01],\n          [1.2177e-01, 4.8385e-01, 3.3895e-01,  ..., 8.8196e-01,\n           6.8876e-01, 5.1208e-01],\n          ...,\n          [4.8053e-02, 5.5786e-01, 2.2046e-01,  ..., 4.0608e-01,\n           4.3846e-01, 6.7422e-01],\n          [6.4894e-01, 1.1976e-01, 7.5831e-01,  ..., 3.5216e-02,\n           3.3733e-01, 7.2352e-01],\n          [5.0859e-01, 9.0252e-01, 2.4358e-01,  ..., 8.1623e-02,\n           8.5563e-01, 5.9489e-01]]],\n\n\n        [[[8.5758e-01, 5.0259e-01, 2.2895e-01,  ..., 7.2534e-01,\n           6.2372e-01, 3.8066e-01],\n          [7.8871e-01, 5.3361e-01, 3.6473e-01,  ..., 9.4121e-01,\n           3.9087e-01, 7.4879e-01],\n          [7.4753e-01, 9.4649e-02, 9.1480e-01,  ..., 2.8185e-01,\n           5.5405e-01, 2.2970e-02],\n          ...,\n          [9.0805e-02, 6.2253e-01, 6.0199e-01,  ..., 1.5496e-01,\n           7.7484e-01, 7.8562e-01],\n          [8.4393e-01, 5.8000e-01, 3.3140e-01,  ..., 3.0217e-01,\n           6.9190e-01, 7.5337e-01],\n          [7.4236e-02, 3.3875e-01, 7.1654e-01,  ..., 1.1464e-01,\n           3.2175e-01, 7.0329e-01]],\n\n         [[2.2687e-01, 3.9926e-01, 2.9424e-01,  ..., 8.4405e-01,\n           9.5913e-01, 1.6203e-01],\n          [9.3196e-01, 4.7000e-01, 5.7360e-01,  ..., 4.2601e-01,\n           9.0416e-01, 4.8289e-01],\n          [3.9477e-01, 9.8939e-01, 4.1636e-02,  ..., 8.6451e-01,\n           9.0905e-01, 4.9790e-01],\n          ...,\n          [6.4355e-01, 8.8000e-01, 1.0445e-01,  ..., 7.8221e-01,\n           5.7276e-01, 1.7615e-01],\n          [8.8080e-01, 2.5258e-01, 2.3813e-01,  ..., 4.2162e-01,\n           5.0370e-01, 6.3670e-01],\n          [6.5094e-01, 1.0692e-01, 1.5657e-01,  ..., 7.2190e-01,\n           8.3334e-01, 6.2047e-01]],\n\n         [[5.8921e-01, 2.9393e-02, 5.3733e-01,  ..., 9.0401e-01,\n           6.7825e-01, 3.9072e-01],\n          [6.2842e-01, 7.9033e-01, 9.4264e-02,  ..., 1.8470e-01,\n           1.8805e-01, 3.8611e-01],\n          [8.3983e-01, 5.4243e-01, 2.3884e-02,  ..., 6.7560e-01,\n           9.5191e-01, 7.3957e-01],\n          ...,\n          [8.3078e-01, 7.9420e-01, 3.9803e-01,  ..., 3.3362e-01,\n           2.0503e-01, 7.3426e-01],\n          [9.6050e-01, 8.5461e-01, 1.5580e-01,  ..., 1.3128e-01,\n           9.5808e-01, 2.9362e-01],\n          [4.3694e-01, 6.7675e-01, 6.8504e-01,  ..., 7.1935e-01,\n           2.1696e-01, 4.8774e-01]]],\n\n\n        [[[1.4773e-01, 3.3451e-01, 1.8007e-01,  ..., 9.4581e-01,\n           9.0649e-01, 8.9537e-01],\n          [8.1063e-01, 8.1132e-01, 9.3650e-02,  ..., 6.1329e-01,\n           5.3944e-02, 2.7727e-01],\n          [4.4024e-02, 5.8211e-01, 5.8560e-01,  ..., 5.2487e-01,\n           4.5608e-01, 1.3279e-01],\n          ...,\n          [3.4656e-01, 1.5653e-01, 7.1409e-01,  ..., 6.8315e-01,\n           4.0251e-01, 8.6468e-01],\n          [1.7268e-01, 6.2379e-01, 1.2549e-01,  ..., 8.7382e-01,\n           7.5412e-01, 8.3509e-02],\n          [1.7227e-01, 2.2295e-03, 1.1874e-01,  ..., 9.6107e-01,\n           6.2720e-01, 6.9681e-01]],\n\n         [[6.7404e-01, 5.0970e-02, 9.6371e-01,  ..., 9.8963e-01,\n           8.4315e-01, 3.0069e-01],\n          [1.6334e-02, 2.6652e-01, 8.0230e-01,  ..., 7.6979e-01,\n           5.7431e-01, 9.4003e-01],\n          [2.2258e-01, 7.3379e-01, 6.4339e-01,  ..., 5.3996e-01,\n           8.3269e-01, 2.7454e-01],\n          ...,\n          [7.2833e-01, 6.7732e-01, 7.9177e-01,  ..., 9.4095e-01,\n           3.0549e-01, 5.1538e-01],\n          [5.2292e-01, 1.3544e-01, 2.0652e-01,  ..., 4.5612e-01,\n           4.1750e-01, 2.3115e-01],\n          [1.1252e-01, 9.1131e-01, 5.4182e-01,  ..., 2.6223e-01,\n           2.4236e-01, 3.5460e-01]],\n\n         [[1.1796e-01, 9.0495e-01, 7.8728e-01,  ..., 1.7108e-01,\n           1.4245e-01, 2.8912e-03],\n          [6.5686e-01, 5.8450e-01, 8.6761e-01,  ..., 1.1502e-01,\n           6.2104e-01, 9.6535e-02],\n          [3.1113e-01, 2.2779e-01, 7.3607e-01,  ..., 6.6733e-01,\n           9.1577e-01, 6.7250e-01],\n          ...,\n          [4.2399e-01, 8.9680e-01, 5.1337e-01,  ..., 9.8406e-01,\n           6.2263e-02, 3.1401e-01],\n          [6.6615e-01, 9.9477e-01, 2.0322e-01,  ..., 5.4914e-01,\n           9.7659e-01, 2.1559e-02],\n          [1.9797e-01, 3.0624e-01, 3.0898e-01,  ..., 9.2221e-02,\n           3.9959e-01, 5.1006e-01]]]])"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transpose\n",
    "a=torch.rand(4,3,32,32)\n",
    "a.shape\n",
    "a.transpose(1,3).contiguous().view(4,3*32*32).view(4,32,32,3).transpose(1,3)\n",
    "#跟踪维度信息,这样就完全不变了"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 25, 32, 4])"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#permute\n",
    "a=torch.rand(4,3,25,32)\n",
    "a.permute(1,2,3,0).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([10, 3, 20])"
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cat拼接\n",
    "a=torch.rand(4,3,20)\n",
    "b=torch.rand(6,3,20)\n",
    "torch.cat([a,b],dim=0).shape\n",
    "#dim要一样,后面的维度一样,外部盒子一样内部才有机会合并"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 2, 3, 20])"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stack维度必须完全一样\n",
    "a=torch.rand(4,3,20)\n",
    "b=torch.rand(4,3,20)\n",
    "torch.stack([a,b],dim=1).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([1, 3, 20]), torch.Size([3, 3, 20]))"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.rand(4,3,20)\n",
    "aa,bb=c.split([1,3],dim=0)\n",
    "aa.shape,bb.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([4, 1, 20]), torch.Size([4, 2, 20]))"
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.rand(4,3,20)\n",
    "aa,bb=c.split([1,2],dim=1)\n",
    "aa.shape,bb.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([3, 3, 20]), torch.Size([1, 3, 20]))"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.rand(4,3,20)\n",
    "aa,bb=c.split(3,dim=0)#每块为3,不够的一块\n",
    "aa.shape,bb.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_3028/507317110.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mc\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrand\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m6\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m3\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m20\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0maa\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbb\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdd\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;31m#每块为2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0maa\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mbb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "c=torch.rand(6,3,20)\n",
    "aa,bb,dd=c.split(2,dim=0)#每块为2\n",
    "aa.shape,bb.shape,dd.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([2, 3, 20]), torch.Size([2, 3, 20]), torch.Size([2, 3, 20]))"
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#按数量拆分\n",
    "c=torch.rand(6,3,20)\n",
    "aa,bb,dd=c.chunk(3,dim=0)#\n",
    "aa.shape,bb.shape,dd.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([6, 1, 20]), torch.Size([6, 1, 20]), torch.Size([6, 1, 20]))"
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#按数量拆分\n",
    "c=torch.rand(6,3,20)\n",
    "aa,bb,dd=c.chunk(3,dim=1)#\n",
    "aa.shape,bb.shape,dd.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "data": {
      "text/plain": "(torch.Size([6, 3, 7]), torch.Size([6, 3, 7]), torch.Size([6, 3, 6]))"
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#按数量拆分\n",
    "c=torch.rand(6,3,20)\n",
    "aa,bb,dd=c.chunk(3,dim=2)#\n",
    "aa.shape,bb.shape,dd.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2200, 0.6658, 0.9291, 0.0547],\n",
      "        [0.6090, 0.8269, 0.1153, 0.2080],\n",
      "        [0.7866, 0.4386, 0.6425, 0.2577]])\n",
      "tensor([0.4405, 0.4444, 0.4934, 0.8268])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.6604, 1.1102, 1.4224, 0.8815],\n        [1.0494, 1.2713, 0.6087, 1.0348],\n        [1.2270, 0.8830, 1.1359, 1.0846]])"
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加法\n",
    "a=torch.rand(3,4)\n",
    "print(a)\n",
    "b=torch.rand(4)#自动broadcast\n",
    "print(b)\n",
    "a+b"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2416, 0.4702, 0.6719, 0.0831],\n",
      "        [0.4038, 0.1319, 0.1636, 0.8846],\n",
      "        [0.9285, 0.9121, 0.5395, 0.8212]])\n",
      "tensor([0.7156, 0.3621, 0.0325, 0.3718])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[0.9572, 0.8323, 0.7045, 0.4548],\n        [1.1194, 0.4940, 0.1962, 1.2564],\n        [1.6441, 1.2742, 0.5720, 1.1929]])"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加法,类似有sub,mul,div,注意元素相乘和矩阵相乘的区别\n",
    "a=torch.rand(3,4)\n",
    "print(a)\n",
    "b=torch.rand(4)#自动broadcast\n",
    "print(b)\n",
    "torch.add(a,b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2],\n",
      "        [1, 2]])\n",
      "tensor([[1, 2],\n",
      "        [2, 2]])\n",
      "tensor([[ 7, 10],\n",
      "        [ 5,  6]])\n",
      "tensor([[ 7, 10],\n",
      "        [ 5,  6]])\n",
      "tensor([[3, 4],\n",
      "        [2, 4]])\n",
      "tensor([[ 7, 10],\n",
      "        [ 5,  6]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.tensor([[3,2],[1,2]])\n",
    "print(a)\n",
    "b=torch.tensor([[1,2],[2,2]])\n",
    "print(b)\n",
    "print(a.mm(b))\n",
    "print(a.matmul(b))\n",
    "print(a*b)\n",
    "print(a@b)\n",
    "#mm,matmul,@三者一样"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512])\n",
      "torch.Size([4, 64])\n",
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "#降维\n",
    "x=torch.rand(4,784)\n",
    "w=torch.rand(512,784)\n",
    "y=(x@w.t()).shape\n",
    "print(y)\n",
    "#w.t()降维矩阵\n",
    "w2=torch.rand(64,512)\n",
    "y2=(x@w.t()@w2.t()).shape\n",
    "print(y2)\n",
    "w3=torch.rand(10,64)\n",
    "y3=(x@w.t()@w2.t()@w3.t()).shape\n",
    "print(y3)\n",
    "#数据在tensor中流动,tensorflow"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[18.7279, 14.7107, 18.4394, 15.6507],\n          [19.1696, 16.6734, 18.9103, 16.6015],\n          [18.8771, 14.1585, 17.3858, 14.7576],\n          [17.3598, 14.8063, 18.6357, 15.9805],\n          [16.5534, 13.9745, 16.7825, 14.5054],\n          [17.5820, 16.0427, 16.8012, 14.7147],\n          [16.9087, 16.5778, 18.2923, 13.4523],\n          [18.2601, 15.7008, 17.6513, 16.2957],\n          [17.1674, 15.1047, 19.2119, 14.9162],\n          [17.6090, 14.7501, 18.6883, 15.3758],\n          [16.1328, 13.0522, 15.3556, 13.8331],\n          [16.5882, 15.1239, 18.1456, 15.7856]],\n\n         [[17.7835, 16.3259, 16.4364, 15.1189],\n          [15.6879, 14.0212, 13.6035, 12.3450],\n          [16.8754, 14.4348, 16.3223, 13.8010],\n          [18.3611, 15.3241, 15.9442, 13.4834],\n          [17.4579, 14.8192, 15.4611, 13.7239],\n          [17.1787, 15.8363, 17.2659, 14.1529],\n          [18.4845, 14.7949, 16.4287, 15.3305],\n          [17.0696, 15.7756, 16.0140, 13.0160],\n          [17.0211, 14.7502, 16.5364, 13.7778],\n          [18.2802, 16.4269, 17.7120, 14.1473],\n          [16.4001, 14.8476, 15.2211, 13.8963],\n          [18.6201, 16.0581, 17.2276, 15.3648]],\n\n         [[16.8181, 16.9451, 17.2262, 16.1358],\n          [17.2278, 18.1162, 16.3557, 16.4194],\n          [16.0546, 16.4673, 15.8795, 16.0523],\n          [18.6094, 17.7991, 16.1341, 17.3610],\n          [19.5835, 18.5869, 17.6822, 17.0890],\n          [15.9585, 17.9517, 15.9959, 15.0229],\n          [15.8988, 16.3645, 15.7284, 15.1492],\n          [17.4099, 17.1026, 17.2068, 16.1020],\n          [16.7604, 17.1753, 18.1176, 16.9168],\n          [17.8050, 17.4178, 16.3788, 15.8603],\n          [17.2642, 18.0866, 16.9569, 17.5004],\n          [19.4642, 20.4244, 18.9788, 18.7669]]],\n\n\n        [[[14.9901, 15.1357, 15.1824, 16.8687],\n          [15.1352, 14.4227, 13.8368, 14.6050],\n          [16.3861, 15.0666, 15.8134, 15.8150],\n          [11.7702, 10.7041, 12.4858, 12.0679],\n          [16.0279, 14.3983, 16.3340, 16.3005],\n          [14.6283, 13.5249, 14.7535, 15.1682],\n          [12.6537, 12.5848, 12.7738, 13.0500],\n          [12.8028, 12.7012, 12.8066, 14.7585],\n          [14.8326, 13.7123, 14.6830, 14.2039],\n          [11.8030, 10.4503, 11.6216, 12.9214],\n          [15.2069, 14.6599, 14.9656, 16.6120],\n          [16.5837, 15.4076, 17.0664, 17.2164]],\n\n         [[15.6022, 19.0003, 15.7461, 16.0060],\n          [18.5660, 17.5432, 16.3119, 17.0927],\n          [14.0508, 15.8368, 14.3497, 14.0487],\n          [15.3201, 15.4305, 13.4629, 14.2551],\n          [15.4079, 15.7775, 14.0172, 14.7255],\n          [15.8860, 15.7211, 14.1686, 15.7631],\n          [14.2448, 15.0336, 12.4374, 13.6940],\n          [16.6315, 14.9819, 15.4400, 14.7196],\n          [13.3591, 14.0270, 12.8432, 13.1685],\n          [14.7630, 15.0096, 13.5853, 14.7575],\n          [15.3972, 14.4547, 13.5920, 14.7920],\n          [13.0452, 13.9828, 12.4189, 13.5215]],\n\n         [[19.9477, 15.5122, 18.5006, 20.5588],\n          [19.3325, 16.2157, 18.6551, 20.8820],\n          [14.4897, 11.9133, 12.6947, 15.1086],\n          [17.1480, 13.0721, 16.1081, 18.0986],\n          [15.8762, 13.2085, 14.9603, 16.4761],\n          [16.3311, 14.4427, 14.5906, 18.0580],\n          [16.1425, 13.5023, 16.1249, 16.4232],\n          [16.3197, 13.1379, 15.0688, 18.7017],\n          [17.9591, 15.2705, 17.0795, 19.9268],\n          [12.9127, 12.9271, 11.7209, 14.8395],\n          [17.9333, 13.3736, 16.9877, 18.0100],\n          [16.3028, 14.1117, 15.9489, 18.6736]]],\n\n\n        [[[16.5860, 18.7667, 18.5963, 17.3931],\n          [15.5506, 15.8517, 14.4913, 15.3001],\n          [13.2450, 16.3399, 16.6255, 15.6342],\n          [13.9707, 14.4162, 13.9469, 15.0517],\n          [15.2244, 15.1449, 16.0021, 15.7246],\n          [14.1148, 15.4510, 15.0178, 14.1798],\n          [17.6025, 18.3273, 17.4962, 18.6037],\n          [15.2960, 15.7576, 14.9827, 14.0127],\n          [13.3382, 14.3704, 14.2260, 12.9276],\n          [15.5275, 17.5262, 15.7991, 17.0696],\n          [14.9069, 16.0467, 16.7433, 15.8102],\n          [13.3980, 15.0426, 14.4314, 14.5808]],\n\n         [[21.7395, 18.1471, 21.4761, 17.7414],\n          [21.2497, 15.5620, 20.1318, 17.8479],\n          [14.8193, 12.5407, 13.1612, 15.4002],\n          [17.7022, 15.2977, 16.2896, 15.1877],\n          [18.8971, 15.0446, 16.9157, 14.9327],\n          [18.7230, 15.5255, 17.0834, 15.2674],\n          [19.8331, 16.3516, 18.7731, 16.7196],\n          [17.1899, 13.6513, 16.0400, 15.3160],\n          [20.5653, 17.6248, 18.7080, 17.8558],\n          [19.0243, 14.6501, 17.4495, 14.8498],\n          [19.1508, 16.5154, 18.3845, 16.0688],\n          [15.9088, 13.0006, 14.6958, 14.3168]],\n\n         [[15.0125, 14.3717, 12.8286, 14.1567],\n          [16.1871, 15.6702, 15.2773, 16.3392],\n          [16.4282, 18.4130, 14.5243, 15.7413],\n          [16.7957, 18.6319, 15.4358, 16.8990],\n          [18.8677, 18.9302, 15.7955, 17.4966],\n          [15.6463, 16.2995, 15.0673, 15.6198],\n          [16.0414, 16.4431, 13.4246, 15.6856],\n          [16.8476, 17.6792, 15.7271, 17.3058],\n          [14.5037, 14.8751, 12.9099, 13.4425],\n          [16.5940, 17.8192, 15.1402, 16.4512],\n          [16.9966, 17.6406, 15.4062, 15.9369],\n          [15.8545, 15.8334, 13.3770, 14.7691]]],\n\n\n        [[[16.0308, 17.4436, 17.0794, 14.5809],\n          [18.3884, 19.6296, 18.3698, 16.3520],\n          [17.1492, 19.9120, 18.2796, 16.5342],\n          [16.5304, 17.2934, 15.8436, 14.5279],\n          [13.4054, 14.9339, 15.2998, 12.9807],\n          [15.6770, 17.6186, 17.5206, 15.2655],\n          [13.1798, 16.2512, 16.1380, 13.7907],\n          [15.6075, 17.3481, 16.8327, 15.5475],\n          [13.1071, 15.8594, 14.3998, 13.6995],\n          [13.7856, 17.5356, 16.5813, 13.3182],\n          [15.2240, 18.9226, 17.7799, 15.6819],\n          [16.3781, 18.6867, 17.0577, 16.3162]],\n\n         [[18.7028, 18.0573, 15.4531, 17.1211],\n          [14.7298, 13.8949, 13.2282, 14.2982],\n          [17.6621, 16.9307, 14.7636, 15.6320],\n          [17.3339, 15.4291, 13.6345, 14.1760],\n          [18.6086, 17.3622, 14.8923, 17.5628],\n          [16.6943, 16.7637, 13.7005, 14.7981],\n          [15.8623, 15.4267, 13.6072, 15.1909],\n          [18.2922, 17.0066, 14.9091, 16.3577],\n          [17.8786, 16.3944, 15.6616, 15.7026],\n          [17.5851, 16.2529, 14.5634, 15.5386],\n          [17.1691, 16.3451, 15.0346, 16.1196],\n          [17.2570, 14.3480, 13.8161, 12.7756]],\n\n         [[16.0024, 16.9527, 16.7921, 15.4569],\n          [17.4863, 17.7996, 19.5262, 18.1837],\n          [14.7352, 14.8761, 16.5545, 14.5893],\n          [15.5946, 16.7878, 16.5264, 14.5988],\n          [15.1038, 15.1202, 16.9044, 14.8095],\n          [14.9759, 18.9044, 17.7908, 16.6522],\n          [16.7286, 15.8405, 17.2446, 15.1989],\n          [16.5244, 17.2426, 18.7913, 16.8547],\n          [16.0192, 16.8624, 17.0037, 15.0927],\n          [15.4009, 16.5201, 17.1276, 14.7917],\n          [14.6051, 14.4671, 15.4097, 15.8066],\n          [16.8694, 17.0966, 18.0980, 16.2609]]]])"
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#三维矩阵,四维矩阵乘法\n",
    "a=torch.rand(4,3,12,64)\n",
    "b=torch.rand(4,3,64,4)\n",
    "a.matmul(b)\n",
    "#mm会报错,对于高维矩阵,要用matmul\n",
    "#matmul是后两维度相乘,就是多个矩阵对并行相乘\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[17.6791, 16.5329, 17.7322, 14.2755],\n          [16.8261, 16.0999, 15.6053, 14.0312],\n          [16.9536, 17.7834, 16.3790, 14.8252],\n          [16.8188, 17.8827, 16.8425, 15.3597],\n          [20.2786, 17.2437, 18.1378, 15.0270],\n          [16.0006, 17.3413, 17.0755, 15.0517],\n          [17.7110, 15.5447, 16.8860, 15.2984],\n          [16.4113, 16.1740, 17.2216, 13.9614],\n          [16.3866, 15.9782, 15.5784, 14.2969],\n          [13.3035, 12.2432, 13.0641, 10.8445],\n          [17.8015, 16.8325, 17.1840, 14.8672],\n          [16.8763, 17.1841, 16.5568, 15.3770]],\n\n         [[17.4315, 16.7569, 16.7822, 16.0238],\n          [16.7256, 17.6839, 17.6801, 14.6609],\n          [16.0267, 14.4685, 15.9524, 13.4161],\n          [17.5120, 16.9284, 17.4674, 15.9492],\n          [19.3057, 18.4845, 18.5468, 15.8730],\n          [16.8840, 16.4994, 16.2741, 14.7507],\n          [15.6611, 17.4749, 15.7679, 14.4022],\n          [19.0372, 19.8527, 18.9184, 17.5505],\n          [15.4764, 16.9339, 16.1043, 14.4187],\n          [16.8318, 15.2217, 16.3249, 13.9945],\n          [17.7034, 16.5753, 17.7808, 15.3621],\n          [15.0081, 15.6544, 15.3272, 14.6588]],\n\n         [[17.7617, 16.2458, 17.4071, 15.2422],\n          [17.4898, 18.5659, 17.5193, 15.5917],\n          [16.2397, 15.8886, 16.8378, 14.9602],\n          [17.3822, 17.4524, 17.6736, 15.3386],\n          [14.2857, 14.0080, 13.2064, 12.0724],\n          [15.7910, 17.1107, 16.6676, 14.1293],\n          [16.8554, 14.5298, 17.7352, 14.8900],\n          [16.3849, 16.2517, 16.9192, 15.4799],\n          [17.0735, 15.2707, 16.0085, 15.0193],\n          [18.8043, 17.0136, 17.8147, 16.7829],\n          [16.0577, 14.8415, 16.2347, 14.3185],\n          [15.7949, 15.4172, 16.3854, 13.6511]]],\n\n\n        [[[14.8056, 14.9272, 16.6963, 16.0694],\n          [15.8772, 16.6103, 17.6609, 18.9194],\n          [13.6902, 14.1857, 16.1655, 17.1749],\n          [14.8819, 16.4990, 17.6962, 19.0456],\n          [13.5331, 14.4020, 15.8896, 16.5512],\n          [15.5541, 17.9274, 19.1005, 19.6464],\n          [13.4159, 15.2649, 16.0021, 15.6456],\n          [15.3460, 17.0418, 17.1578, 18.3471],\n          [12.6420, 13.9105, 14.3216, 14.9172],\n          [11.7582, 14.6061, 15.3773, 15.7717],\n          [14.0532, 16.5963, 15.9091, 17.0587],\n          [14.1269, 16.0569, 16.1662, 16.9996]],\n\n         [[13.9288, 15.3959, 17.1404, 17.6163],\n          [12.4953, 14.1108, 13.6852, 14.3244],\n          [13.8362, 15.3092, 14.9916, 16.2591],\n          [13.8239, 14.9776, 15.5261, 15.8078],\n          [14.3554, 16.6393, 17.9956, 17.9766],\n          [16.0318, 18.1788, 17.4482, 18.3558],\n          [15.3309, 15.4246, 16.8234, 16.8019],\n          [15.6408, 16.7578, 17.1826, 17.8491],\n          [12.9979, 14.8256, 13.7710, 14.5987],\n          [14.1605, 15.4532, 16.0105, 16.8656],\n          [13.2906, 15.7374, 16.5015, 16.8252],\n          [13.9598, 15.7001, 16.9991, 17.2817]],\n\n         [[15.6724, 15.9806, 17.0940, 17.4206],\n          [14.2614, 14.6505, 15.7021, 16.2424],\n          [14.8882, 17.1386, 16.5924, 17.2710],\n          [14.6516, 15.8559, 16.0720, 16.1542],\n          [12.4807, 15.5314, 16.1385, 15.7787],\n          [14.6920, 16.8935, 17.7990, 18.9279],\n          [13.9487, 15.8581, 14.9970, 15.8432],\n          [13.5505, 13.8473, 15.2882, 15.7143],\n          [14.5478, 18.0387, 16.8048, 16.8983],\n          [14.0754, 13.6500, 15.2448, 15.6046],\n          [13.1229, 15.2430, 15.5936, 16.4403],\n          [15.1955, 15.4050, 16.5307, 17.3142]]],\n\n\n        [[[15.8436, 16.4934, 15.3735, 16.0488],\n          [14.6681, 15.8296, 15.2804, 15.1209],\n          [15.3127, 14.3116, 17.0349, 15.3405],\n          [15.8692, 15.5494, 16.9023, 15.8268],\n          [17.0407, 17.6132, 17.8428, 18.6948],\n          [13.3896, 14.0014, 14.6332, 14.2274],\n          [16.2916, 14.6772, 17.3284, 16.2170],\n          [15.4283, 16.2284, 16.3450, 15.8497],\n          [15.5099, 16.5350, 17.2886, 17.9023],\n          [16.2463, 17.2463, 17.8389, 17.1145],\n          [15.8070, 14.6140, 14.8218, 14.5272],\n          [16.9423, 16.2003, 18.4344, 18.4370]],\n\n         [[18.9266, 18.4964, 19.8045, 19.7774],\n          [16.3739, 17.6999, 18.9883, 18.6132],\n          [16.0012, 17.5887, 15.4719, 17.0448],\n          [15.0978, 14.2484, 15.0034, 13.8413],\n          [13.7748, 14.6108, 15.6525, 15.3859],\n          [16.2439, 16.9388, 17.2409, 17.9150],\n          [16.6647, 15.3984, 17.8083, 16.8057],\n          [15.2958, 14.7819, 17.0417, 15.5900],\n          [16.9251, 16.8701, 16.9857, 16.4562],\n          [17.0076, 17.1689, 18.6425, 16.8391],\n          [14.7449, 13.7633, 15.3817, 14.8556],\n          [15.3428, 15.8423, 14.8646, 16.0880]],\n\n         [[12.0832, 13.5212, 14.3590, 14.4804],\n          [15.3140, 14.3839, 15.2541, 15.9874],\n          [17.1479, 16.4526, 16.6762, 16.8908],\n          [15.7863, 13.8456, 15.8230, 13.9109],\n          [15.0868, 14.6454, 14.9092, 15.3256],\n          [17.0304, 18.3023, 18.5720, 17.6828],\n          [15.3801, 16.0282, 17.8640, 16.3085],\n          [18.5203, 18.9056, 18.8459, 18.2676],\n          [17.4349, 17.3519, 19.4277, 17.7377],\n          [13.9866, 14.4693, 13.5244, 14.4044],\n          [16.6644, 16.3899, 16.7245, 16.8203],\n          [18.2269, 18.3829, 17.5058, 17.6367]]],\n\n\n        [[[17.4615, 17.2402, 17.7045, 16.1391],\n          [16.6173, 15.9193, 19.6074, 16.5839],\n          [17.9651, 17.5634, 20.2880, 17.1350],\n          [14.8383, 14.6419, 17.0183, 14.6501],\n          [16.3777, 15.1383, 17.4386, 15.5479],\n          [16.4814, 16.8336, 19.2261, 15.5331],\n          [17.4644, 16.9245, 19.7389, 16.4327],\n          [14.8202, 14.2884, 16.7153, 12.8218],\n          [16.3120, 16.0429, 17.6900, 15.3982],\n          [16.8379, 15.7061, 19.0171, 15.5800],\n          [14.7613, 15.1996, 17.4715, 13.7469],\n          [17.1586, 15.4067, 18.0098, 15.0576]],\n\n         [[15.8309, 14.8653, 19.1073, 15.5016],\n          [17.2903, 17.0283, 20.5553, 17.3218],\n          [16.0768, 15.5902, 17.9641, 16.0146],\n          [15.9845, 16.4902, 17.3043, 14.2531],\n          [16.5036, 15.6533, 18.6913, 15.4350],\n          [13.3594, 13.8306, 15.4871, 13.5336],\n          [15.3950, 13.7906, 16.9658, 14.1416],\n          [16.7048, 18.7761, 19.9247, 16.7806],\n          [17.1945, 17.3195, 20.9622, 17.4069],\n          [16.0851, 13.7039, 17.4845, 14.9849],\n          [15.8323, 15.5921, 18.5185, 14.9691],\n          [15.7980, 15.6252, 18.6992, 14.9127]],\n\n         [[17.6360, 17.2914, 19.5429, 16.1817],\n          [15.7276, 15.3607, 18.0040, 14.4526],\n          [14.6502, 14.7211, 17.4024, 13.8613],\n          [16.6903, 14.9437, 17.4018, 14.1080],\n          [16.5151, 15.7534, 19.6037, 14.8031],\n          [14.6141, 14.4968, 15.8184, 13.7959],\n          [14.6869, 14.9704, 16.3482, 12.6915],\n          [17.5121, 16.7093, 20.6327, 17.3179],\n          [16.0176, 16.4177, 17.9198, 14.7110],\n          [17.9732, 16.2441, 19.6781, 14.8828],\n          [17.0757, 16.9493, 19.1677, 14.9664],\n          [16.2836, 16.0668, 17.5376, 14.7220]]]])"
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(4,3,12,64)\n",
    "b=torch.rand(4,1,64,4)\n",
    "#先转换至(4,3,64,4),再矩阵相称\n",
    "a.matmul(b)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9, 9],\n",
      "        [9, 9]])\n",
      "tensor([[9, 9],\n",
      "        [9, 9]])\n",
      "tensor([[27, 27],\n",
      "        [27, 27]])\n",
      "tensor([[1.7321, 1.7321],\n",
      "        [1.7321, 1.7321]])\n",
      "tensor([[0.5774, 0.5774],\n",
      "        [0.5774, 0.5774]])\n",
      "tensor([[1.7321, 1.7321],\n",
      "        [1.7321, 1.7321]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.full([2,2],3)#全为3\n",
    "print(a.pow(2))\n",
    "print(a**2)\n",
    "print(a**3)\n",
    "print(torch.sqrt(a.to(torch.double)))#平方跟\n",
    "print(torch.rsqrt(a.to(torch.double)))#平方跟的倒数\n",
    "print(a**(0.5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4463, 0.2846],\n",
      "        [0.0529, 0.9397]])\n",
      "tensor([[1.5626, 1.3292],\n",
      "        [1.0544, 2.5591]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[-0.8067, -1.2567],\n        [-2.9384, -0.0622]])"
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.rand(2,2)\n",
    "print(a)\n",
    "print(torch.exp(a))#e**a\n",
    "torch.log(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(3.), tensor(4.), tensor(3.), tensor(0.1400))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor(3.14)\n",
    "a.floor(),a.ceil(),a.trunc(),a.frac()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(7.)"
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=torch.tensor(3.14)\n",
    "#四舍五入\n",
    "a.round()\n",
    "b=torch.tensor(6.74)\n",
    "#四舍五入\n",
    "b.round()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4147,  8.8985, 10.6381],\n",
      "        [13.3255,  1.1394,  6.2551]])\n",
      "tensor(13.3255) tensor(6.2551)\n",
      "tensor([[ 6.0000,  8.8985, 10.0000],\n",
      "        [10.0000,  6.0000,  6.2551]])\n"
     ]
    }
   ],
   "source": [
    "grad=torch.rand(2,3)*15\n",
    "print(grad)\n",
    "print(grad.max(),grad.median())\n",
    "print(grad.clamp(6,10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 3],\n",
      "        [6, 3]])\n",
      "tensor(108)\n",
      "tensor(14)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor([1, 0])\n",
      "torch.return_types.max(\n",
      "values=tensor([3, 6]),\n",
      "indices=tensor([1, 0]))\n"
     ]
    }
   ],
   "source": [
    "#属性统计\n",
    "#norm求范数\n",
    "a=torch.tensor([[2,3],[6,3]])\n",
    "print(a)\n",
    "print(a.prod())#prod累积\n",
    "print(a.sum())#求和\n",
    "print(a.argmax())\n",
    "print(a.argmin())#获取打平后的相应的索引\n",
    "print(a.argmax(dim=1))\n",
    "print(a.max(dim=1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.0000e+01, -4.2857e+01, -3.5714e+01, -2.8571e+01, -2.1429e+01,\n",
      "        -1.4286e+01, -7.1429e+00,  4.7684e-07,  7.1429e+00,  1.4286e+01,\n",
      "         2.1429e+01,  2.8571e+01,  3.5714e+01,  4.2857e+01,  5.0000e+01])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([1.9287e-22, 2.4399e-19, 3.0866e-16, 3.9047e-13, 4.9396e-10, 6.2487e-07,\n        7.8987e-04, 5.0000e-01, 9.9921e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n        1.0000e+00, 1.0000e+00, 1.0000e+00])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a=torch.linspace(-50,50,15)\n",
    "print(a)\n",
    "torch.sigmoid(a)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}